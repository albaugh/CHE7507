{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcA1Dw0tOWuZ7diw9TmnlQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albaugh/CHE7507/blob/main/validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alex Albaugh.  Wayne State.  CHE 5995/7507.  Lecture 8.  Winter 2026."
      ],
      "metadata": {
        "id": "55wAmsXm2VmM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will demonstrate different methods of validation- splitting your data into training and testing blocks so that you can estimate the testing error.  This is useful for directly estimating the error and also for selecting hyperparameters, such as the degree of polynomial regression or a $\\lambda$ parameter in regularization.  \n",
        "\n",
        "We'll demonstrate these methods as we build a model to predict the power output from a combined cycle power plant.  A combined cycle power plant generates combustion gases from coal, which are then burned in a gas turbine to produce power.  The waste heat from the gas turbine is used to create steam, which is then fed to a steam turbine to generate additional power- hence \"combined cycle.\"  We'll build a model to predict how ambinet conditions affect the power output of the plant.  Our target is electrical power output (PE) in MW, and our features are ambient temperature in Celcius (AT), ambient pressure in millibar (AP), relative humidity in % (RH), and exhaust vacuum in cm Hg (V).  \n",
        "\n",
        "This is a real world data set taken from the University of California, Irvine Machine Learning Repository:\n",
        "https://archive.ics.uci.edu/dataset/294/combined+cycle+power+plant"
      ],
      "metadata": {
        "id": "lrLYGXgY9xCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's load our libraries and data set.  Our features ($\\mathbf{X}$) will be ambient temperature (AT), ambient pressure (AP), relative humidity (RH), and exhaust vacuum (V).  Our target $y$ will be the electric power output (PE)."
      ],
      "metadata": {
        "id": "afFDmTXBBMN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "latwLTKkAg1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read data\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/albaugh/CHE7507/refs/heads/main/Lecture8/combined_cycle_power_plant.csv')\n",
        "\n",
        "#set features\n",
        "X = df[['AT', 'AP', 'RH', 'V']].values\n",
        "\n",
        "#set target\n",
        "y = df['PE'].values"
      ],
      "metadata": {
        "id": "4QP4VnKLAnB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As always, let's get a sense of what we're dealing with."
      ],
      "metadata": {
        "id": "U4btn1HVCOX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of data points: ', y.size)\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "ax.hist(y, bins=50, density=True, color='orange')\n",
        "ax.set_xlabel('Power Output (MW)',fontsize=16)\n",
        "ax.set_ylabel('Likelihood of Power Output (1/MW)',fontsize=16)\n",
        "ax.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eLcSrlA_CSOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "EbXbvgkcAKQ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With validation, we shuffle our data and then split it into a training set and a testing set.  <code>sklearn</code> has a very convenient function called <code>train_test_split</code> that does this automatically.  The <code>test_size</code> keyword determines the fraction of the data that will be put in the test set.  Here we chose 50%."
      ],
      "metadata": {
        "id": "so61jFkQDG6D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8QTtun79uH1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.5)\n",
        "print('Number of training data points: ', y_train.size)\n",
        "print('Number of testing data points: ', y_test.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have training and testing sets, we'll standardize the data and fit it to a model.  As an example, we'll just do some linear regression."
      ],
      "metadata": {
        "id": "D2Xkv9QTEcLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#standardize features\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#fit model\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "QL8pwqzKE4sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can get the training error and test errors from the fitted model."
      ],
      "metadata": {
        "id": "eIanhP2FFC4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_mse = sklearn.metrics.mean_squared_error(y_train, model.predict(X_train))\n",
        "test_mse = sklearn.metrics.mean_squared_error(y_test, model.predict(X_test))\n",
        "\n",
        "print('Training MSE: ', np.round(training_mse, decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(test_mse, decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(training_mse), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(test_mse), decimals=2), ' MW')"
      ],
      "metadata": {
        "id": "eB02MH-9FHaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's redo with only 20% of the data in the test set as another example."
      ],
      "metadata": {
        "id": "JMgRFYTCSnZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train/test split\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
        "print('Number of training data points: ', y_train.size)\n",
        "print('Number of testing data points: ', y_test.size)\n",
        "\n",
        "#standardize features\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "#fit model\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "training_mse = sklearn.metrics.mean_squared_error(y_train, model.predict(X_train))\n",
        "test_mse = sklearn.metrics.mean_squared_error(y_test, model.predict(X_test))\n",
        "\n",
        "print('Training MSE: ', np.round(training_mse, decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(test_mse, decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(training_mse), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(test_mse), decimals=2), ' MW')"
      ],
      "metadata": {
        "id": "HD9u3gMySspx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we split the data randomly and only fit the model once, there is some variability in our training and test error.  Leave-One-Out Cross Validation (LOOCV) fixes this, by using the first data point as the test set, fitting the model to the other n-1 points, and then repeating that procedure for every data point."
      ],
      "metadata": {
        "id": "lszlT3osTGBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leave-One-Out Cross Validation (LOOCV)"
      ],
      "metadata": {
        "id": "razC1wzQTdRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Leave-One-Out Cross Validation, we can make use of <code>sklearn</code>'s <code>LeaveOneOut</code> function.  It will sequentially leave a single data point out of the training set, training the model, and use the left out data point for estimating test error."
      ],
      "metadata": {
        "id": "GrmhKOC6eRFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loocv = sklearn.model_selection.LeaveOneOut()\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "#create an empty array to store the error from each iteration\n",
        "training_errors = []\n",
        "test_errors = []\n",
        "\n",
        "#loop over the data set, holding out each data point sequentially\n",
        "for train_idx, test_idx in loocv.split(X):\n",
        "\n",
        "  #split the data into training and test\n",
        "  X_train, X_test = X[train_idx], X[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  #standardize the data\n",
        "  scaler = sklearn.preprocessing.StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  #train the current model\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  #make predictions on the test error and record them in the arrays\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "  test_mse = sklearn.metrics.mean_squared_error([y_test], [y_pred])  # MSE for this test sample\n",
        "  test_errors.append(test_mse)\n",
        "\n",
        "  #make predictions on the training error and record them in the arrays\n",
        "  y_pred = model.predict(X_train_scaled)\n",
        "  training_mse = sklearn.metrics.mean_squared_error([y_train], [y_pred])  # MSE for this test sample\n",
        "  training_errors.append(training_mse)\n",
        "\n",
        "#print the training and test MSE\n",
        "print('Training MSE: ', np.round(np.mean(training_errors), decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(np.mean(test_errors), decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(np.mean(training_errors)), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(np.mean(test_errors)), decimals=2), ' MW')\n",
        "\n"
      ],
      "metadata": {
        "id": "wFr-m_i-TcnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the <code>make_pipeline</code> and <code>cross_validate</code> functionality, we can make this code compact."
      ],
      "metadata": {
        "id": "cxkemgC-r1nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the scaler, model, and LOOCV\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "loocv = sklearn.model_selection.LeaveOneOut()\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "#create a pipeline with the scaler and model\n",
        "pipeline = sklearn.pipeline.make_pipeline(scaler, model)\n",
        "\n",
        "#this will apply the cross validation automatically and put the results in 'cv_results'\n",
        "#the scoring is the negative of the mean squared error\n",
        "cv_results = sklearn.model_selection.cross_validate(pipeline, X, y, cv=loocv, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "\n",
        "#collect the errors from the validation\n",
        "#since the scores are the negative of MSE, we multiply by -1 to get the MSE\n",
        "training_errors = -1.0*cv_results['train_score']\n",
        "test_errors = -1.0*cv_results['test_score']\n",
        "\n",
        "#print the training and test MSE\n",
        "print('Training MSE: ', np.round(np.mean(training_errors), decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(np.mean(test_errors), decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(np.mean(training_errors)), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(np.mean(test_errors)), decimals=2), ' MW')\n",
        "\n"
      ],
      "metadata": {
        "id": "NNZik71qsLMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LOOCV gives us very error good estimates and they are always consistent.  But as we can see, it can be computationally expensive.  Even with simple linear regression, fitting the model ~9000 different times takes a while, about 2 minutes in this case.  A good intermediate solution is $k$-fold cross validation, where we break the data into $k=$5-10 chunks, using each chunk as a test set and the remainder as training.  In that case we'll only need to fit the model $k$ times."
      ],
      "metadata": {
        "id": "gkIgvqAuuCdz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $k$-Fold Cross Validation"
      ],
      "metadata": {
        "id": "F-AHs5W1utqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we'll set up a 5-fold cross validation on our power plant data and then do 5 linear regressions with each split to estimate the error."
      ],
      "metadata": {
        "id": "0vfHp50vIT_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = sklearn.model_selection.KFold(n_splits=5, shuffle=True)\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "#create an empty array to store the error from each iteration\n",
        "training_errors = []\n",
        "test_errors = []\n",
        "\n",
        "#loop over the data set, holding out each data point sequentially\n",
        "for train_idx, test_idx in kf.split(X):\n",
        "\n",
        "  #split the data into training and test\n",
        "  X_train, X_test = X[train_idx], X[test_idx]\n",
        "  y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "  #standardize the data\n",
        "  scaler = sklearn.preprocessing.StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  #train the current model\n",
        "  model.fit(X_train_scaled, y_train)\n",
        "\n",
        "  #make predictions on the test error and record them in the arrays\n",
        "  y_pred = model.predict(X_test_scaled)\n",
        "  test_mse = sklearn.metrics.mean_squared_error([y_test], [y_pred])  # MSE for this test sample\n",
        "  test_errors.append(test_mse)\n",
        "\n",
        "  #make predictions on the training error and record them in the arrays\n",
        "  y_pred = model.predict(X_train_scaled)\n",
        "  training_mse = sklearn.metrics.mean_squared_error([y_train], [y_pred])  # MSE for this test sample\n",
        "  training_errors.append(training_mse)\n",
        "\n",
        "#print the training and test MSE\n",
        "print('Training MSE: ', np.round(np.mean(training_errors), decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(np.mean(test_errors), decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(np.mean(training_errors)), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(np.mean(test_errors)), decimals=2), ' MW')\n",
        "\n"
      ],
      "metadata": {
        "id": "iWpdLZ33usgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values are fairly consistent and the computational cost is reasonable.  We can also re-write the above code more compactly with <code>make_pipeline</code> and <code>cross_validate</code>."
      ],
      "metadata": {
        "id": "-rhio3JjIoI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the scaler, model, and k-fold cross validation\n",
        "scaler = sklearn.preprocessing.StandardScaler()\n",
        "kf = sklearn.model_selection.KFold(n_splits=5, shuffle=True)\n",
        "model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "#create a pipeline with the scaler and model\n",
        "pipeline = sklearn.pipeline.make_pipeline(scaler, model)\n",
        "\n",
        "#this will apply the cross validation automatically and put the results in 'cv_results'\n",
        "#the scoring is the negative of the mean squared error\n",
        "cv_results = sklearn.model_selection.cross_validate(pipeline, X, y, cv=kf, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "\n",
        "#collect the errors from the validation\n",
        "#since the scores are the negative of MSE, we multiply by -1 to get the MSE\n",
        "training_errors = -1.0*cv_results['train_score']\n",
        "test_errors = -1.0*cv_results['test_score']\n",
        "\n",
        "#print the training and test MSE\n",
        "print('Training MSE: ', np.round(np.mean(training_errors), decimals = 2), ' MW^2')\n",
        "print('Test MSE: ', np.round(np.mean(test_errors), decimals=2), ' MW^2')\n",
        "\n",
        "print('Training RMSE: ', np.round(np.sqrt(np.mean(training_errors)), decimals=2), ' MW')\n",
        "print('Test RMSE: ', np.round(np.sqrt(np.mean(test_errors)), decimals=2), ' MW')\n",
        "\n"
      ],
      "metadata": {
        "id": "jNcSdOWBI701"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's demonstrate how we can use k-fold cross validation to choose the best hyperparameter using a single data set.  We'll use use multiple polynomial regression to find the best polynomial order for our model.  We'll use 10-fold cross validation."
      ],
      "metadata": {
        "id": "ZuxQmFxJJY0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up a range of polynomial orders to test\n",
        "orders = np.arange(1,10)\n",
        "\n",
        "#set up arrays to store training and test error\n",
        "all_training_errors = []\n",
        "all_test_errors = []\n",
        "\n",
        "for ord in orders:\n",
        "  #set up the scaler, model, polynomial features, and k-fold cross validation\n",
        "  kf = sklearn.model_selection.KFold(n_splits=10, shuffle=True)\n",
        "  scaler = sklearn.preprocessing.StandardScaler()\n",
        "  poly = sklearn.preprocessing.PolynomialFeatures(degree=ord, include_bias=False)\n",
        "  model = sklearn.linear_model.LinearRegression()\n",
        "\n",
        "  #create a pipeline with the scaler and model\n",
        "  pipeline = sklearn.pipeline.make_pipeline(poly, scaler, model)\n",
        "\n",
        "  #this will apply the cross validation automatically and put the results in 'cv_results'\n",
        "  #the scoring is the negative of the mean squared error\n",
        "  cv_results = sklearn.model_selection.cross_validate(pipeline, X, y, cv=kf, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "\n",
        "  #collect the errors from the validation\n",
        "  #since the scores are the negative of MSE, we multiply by -1 to get the MSE\n",
        "  training_errors = -1.0*cv_results['train_score']\n",
        "  test_errors = -1.0*cv_results['test_score']\n",
        "\n",
        "  #store the training and test errors\n",
        "  all_training_errors.append(np.mean(training_errors))\n",
        "  all_test_errors.append(np.mean(test_errors))\n",
        "\n",
        "#get the optimal lambda value\n",
        "opt_ord = orders[np.argmin(all_test_errors)]\n",
        "\n",
        "#plot the training and test error vs. lambda\n",
        "fig,ax = plt.subplots()\n",
        "ax.plot(orders, all_training_errors, label='training error', color='gold')\n",
        "ax.plot(orders, all_test_errors, label='test error', color='purple')\n",
        "ax.set_title('optimal polynomial order = '+str(opt_ord), fontsize=20)\n",
        "ax.set_xlabel('polynomial order',fontsize=16)\n",
        "ax.set_ylabel('MSE (MW$^{2}$)',fontsize=16)\n",
        "ax.grid()\n",
        "ax.legend(fontsize=14)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vszJoPvaJ6Vr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}